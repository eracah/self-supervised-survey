{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils import convert_frames,convert_frame\n",
    "import random\n",
    "import data.custom_grids\n",
    "import gym\n",
    "from gym_minigrid.register import env_list\n",
    "from gym_minigrid.minigrid import Grid\n",
    "from functools import partial\n",
    "from data.collectors import get_trans_tuple, DataCollector\n",
    "from functools import partial\n",
    "from data.iterators import PolicyIterator, ListIterator, UnusedPointsIterator\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory(object):\n",
    "    \"\"\"buffer of transitions. you can sample it like a true replay buffer (with replacement) using self.sample\n",
    "    or like normal data iterator used in most supervised learning problems with sellf.__iter__()\"\"\"\n",
    "    \"\"\"Memory is uint8 to save space, then when you sample it converts to float tensor\"\"\"\n",
    "    def __init__(self, capacity=10**6, batch_size=64):\n",
    "        self.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.capacity = capacity\n",
    "        self.batch_size = batch_size\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "        \n",
    "        self.Transition = get_trans_tuple()\n",
    "            \n",
    "    def __add__(self,other_buffer):\n",
    "        buf = copy.deepcopy(self)\n",
    "        buf.memory = buf.memory + other_buffer.memory\n",
    "        return buf\n",
    "    \n",
    "   \n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = self.Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    \n",
    "    def sample(self, batch_size=None, chunk_size=None):\n",
    "        batch_size = self.batch_size if batch_size is None else batch_size\n",
    "        trans = random.sample(self.memory, batch_size)        \n",
    "        return self._convert_raw_sample(trans)\n",
    "        \n",
    "    \n",
    "    def _convert_raw_sample(self,transitions):\n",
    "        \"\"\"converts 8-bit RGB to float and pytorch tensor\"\"\"\n",
    "        # puts all trans objects into one trans object\n",
    "        #trans_batch = self.Transition(*zip(*transitions))\n",
    "        list_of_fields = [list(zip(*field)) for field in zip(*transitions)]\n",
    "        trans = self.Transition(*list_of_fields)\n",
    "        tb_dict = trans._asdict()\n",
    "        #return tb_dict,trans\n",
    "\n",
    "        tb_dict[\"x_coords\"] = torch.tensor(trans.x_coords).long().to(self.DEVICE)\n",
    "        tb_dict[\"y_coords\"] = torch.tensor(trans.y_coords).long().to(self.DEVICE)\n",
    "        tb_dict[\"directions\"] = torch.tensor(trans.directions).long().to(self.DEVICE)\n",
    "        tb_dict[\"xs\"] = torch.stack([convert_frames(np.asarray(trans.xs[i]),to_tensor=True,resize_to=(-1,-1)) for\n",
    "                                                     i in range(len(trans.xs))]).to(self.DEVICE)\n",
    "        tb_dict[\"actions\"] = torch.from_numpy(np.asarray(trans.actions)).to(self.DEVICE)\n",
    "        tb_dict[\"rewards\"] = torch.from_numpy(np.asarray(trans.rewards)).to(self.DEVICE)\n",
    "        tb_dict[\"dones\"] = torch.tensor(trans.dones)\n",
    "        batch = self.Transition(*list(tb_dict.values()))\n",
    "        return batch\n",
    "\n",
    "    def get_zipped_list(self,keys=[\"x_coords\",\n",
    "                                                \"y_coords\",\n",
    "                                                \"directions\"], unique=False):\n",
    "\n",
    "\n",
    "        #TODO: rework this\n",
    "        one_big_trans = self.Transition(*zip(*self.memory))\n",
    "        separated_fields = [one_big_trans._asdict()[key] for key in keys ]\n",
    "        ret_list = list(zip(*separated_fields))\n",
    "        if unique:\n",
    "            ret_list = list(set(ret_list))\n",
    "        return ret_list\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\"Iterator that samples without replacement for replay buffer\n",
    "        It's basically like a standard sgd setup\n",
    "        If you want to sample with replacement like standard replay buffer use self.sample\"\"\"\n",
    "        mem = copy.deepcopy(self.memory)\n",
    "        random.shuffle(mem)\n",
    "        size = len(mem)\n",
    "        for st in range(0, size, self.batch_size):\n",
    "            end = st+self.batch_size if st+self.batch_size <= size else size\n",
    "            raw_sample = self.memory[st:end]\n",
    "            yield self._convert_raw_sample(raw_sample)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "dc = DataCollector(frames_per_trans=3)\n",
    "\n",
    "rb = ReplayMemory(batch_size=batch_size)\n",
    "\n",
    "for i in range(10*batch_size):\n",
    "    trans = dc.collect_transition_per_the_policy()\n",
    "    rb.push(*trans)\n",
    "\n",
    "#tb= rb.sample(batch_size=batch_size)\n",
    "for t in rb:\n",
    "    print(t.x_coords.shape)\n",
    "\n",
    "rb.get_zipped_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BufferFiller(object):\n",
    "    \"\"\"creates and fills replay buffers with transitions\"\"\"\n",
    "    def __init__(self,\n",
    "                 convert_fxn = partial(convert_frame, resize_to=(64,64)),\n",
    "                 env = gym.make(\"MiniGrid-Empty-8x8-v0\"),\n",
    "                 policy= lambda x0: np.random.choice(3), capacity=10000,batch_size=32):\n",
    "        self.env = env\n",
    "        self.policy = policy\n",
    "        self.convert_fxn = convert_fxn\n",
    "        self.capacity = capacity\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "\n",
    "    def split(self, buffer, proportion):\n",
    "        unique_coords = copy.deepcopy(list(set(buffer.get_zipped_list(unique=True))))\n",
    "        len_coords = len(unique_coords)\n",
    "        split_ind = int(proportion*len_coords)\n",
    "        tr_list = unique_coords[:split_ind]\n",
    "\n",
    "        val_list = unique_coords[split_ind:]\n",
    "        buf1 = self.fill_with_list(tr_list)\n",
    "        buf2 = self.fill_with_list(val_list)\n",
    "        del buffer\n",
    "        return buf1, buf2\n",
    "        \n",
    "        \n",
    "    def make_empty_buffer(self):\n",
    "        return ReplayMemory(capacity=self.capacity, batch_size=self.batch_size)\n",
    "    \n",
    "    def fill(self,size):\n",
    "        \"\"\"fill with transitions by just following a policy\"\"\"\n",
    "        buffer = self.make_empty_buffer()\n",
    "        iterator = PolicyIterator(policy=self.policy,\n",
    "                                  env=self.env, \n",
    "                                  convert_fxn=self.convert_fxn)\n",
    "        buffer = self.fill_using_iterator(buffer,size,iterator)\n",
    "        return buffer  \n",
    "\n",
    "    def fill_with_unvisited_states(self, visited_buffer,size):\n",
    "        \"\"\"fill with transitions not present in 'visited_buffer' \"\"\"\n",
    "        buffer = self.make_empty_buffer()\n",
    "        visited_list = copy.deepcopy(visited_buffer.get_zipped_list())\n",
    "        iterator = UnusedPointsIterator(visited_list, \n",
    "                                        env=self.env,\n",
    "                                        convert_fxn=self.convert_fxn)\n",
    "        if size > len(iterator) or size == -1:\n",
    "            size = len(iterator)\n",
    "        assert len(iterator) > 0\n",
    "        buffer = self.fill_using_iterator(buffer,size,iterator)\n",
    "        \n",
    "        assert set(visited_buffer.get_zipped_list()).isdisjoint(set(buffer.get_zipped_list()))\n",
    "        return buffer\n",
    "    \n",
    "    def fill_with_list(self,list_, size=-1):\n",
    "        \"\"\"fill with transitions specified in a list of coordinates and actions \"\"\"\n",
    "        buffer = self.make_empty_buffer()\n",
    "        iterator = ListIterator(list_of_points=list_,\n",
    "                                env=self.env,\n",
    "                                convert_fxn=self.convert_fxn)\n",
    "        \n",
    "        if size > len(iterator) or size == -1:\n",
    "            size = len(iterator)\n",
    "\n",
    "        buffer = self.fill_using_iterator(buffer,size, iterator)\n",
    "        return buffer\n",
    "    \n",
    "    def fill_using_iterator(self, buffer,size, iterator):\n",
    "        \"\"\"fill using the given transition iterator \"\"\"\n",
    "        \n",
    "        global_size=0\n",
    "        while global_size < size:\n",
    "            for i, transition in enumerate(iterator):\n",
    "                buffer.push(*transition)\n",
    "                global_size += 1\n",
    "                if global_size >= size:\n",
    "                    return buffer\n",
    "            iterator.reset()\n",
    "        return buffer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
