{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.4\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "couldn't import doomish\n",
      "Couldn't import doom\n"
     ]
    }
   ],
   "source": [
    "#from data.iterators import PolicyIterator\n",
    "\n",
    "from data.collectors import EpisodeCollector\n",
    "import numpy as np\n",
    "from utils import setup_args\n",
    "import random\n",
    "\n",
    "args = setup_args()\n",
    "\n",
    "args.env_name = \"Pong-v0\"\n",
    "args.model_name = \"vae\"\n",
    "dc = EpisodeCollector(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_action_frame(ep_ind, frame_ind,num = 1, stride=1):\n",
    "    ep = episodes[ep_ind]\n",
    "    frames = []\n",
    "    actions = []\n",
    "    for _ in range(num):\n",
    "        frame = ep._asdict()[\"xs\"][frame_ind]\n",
    "        action = ep._asdict()[\"actions\"][frame_ind]\n",
    "        actions.append(action)\n",
    "        frames.append(frame)\n",
    "        frame_ind += stride\n",
    "    frame = ep._asdict()[\"xs\"][frame_ind]\n",
    "    frames.append(frame)\n",
    "    \n",
    "    trans = dc.get_transition_constructor()(xs=frames, actions=actions)\n",
    "    return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from functools import partial\n",
    "from data.collectors import EpisodeCollector\n",
    "from functools import partial\n",
    "import copy\n",
    "from data.utils import setup_env, convert_frames,convert_frame\n",
    "import math\n",
    "\n",
    "class DataSampler(object):\n",
    "    \"\"\"buffer of episodes. you can sample it like a true replay buffer (with replacement) using self.sample\n",
    "    or like normal data iterator used in most supervised learning problems with sellf.__iter__()\"\"\"\n",
    "    \"\"\"Memory is uint8 to save space, then when you sample it converts to float tensor\"\"\"\n",
    "    def __init__(self,args, batch_size=64):\n",
    "        self.args = args\n",
    "        self.stride = self.args.stride\n",
    "        self.num_frames = self.args.frames_per_trans\n",
    "        self.DEVICE = self.args.device\n",
    "        self.batch_size = batch_size\n",
    "        self.episodes = []                \n",
    "   \n",
    "    def push(self, episode_trans):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        self.episodes.append(episode_trans)\n",
    "\n",
    "    def sample(self,batch_size=None, with_replacement=False):\n",
    "        batch_size = self.batch_size if batch_size is None else batch_size\n",
    "        \n",
    "        #sample indices into frames\n",
    "        all_inds = self.get_all_inds()\n",
    "        all_arr = np.stack(random.choices(all_inds, k=batch_size))\n",
    "        ep_inds, frame_inds = all_arr[:,0], all_arr[:,1]\n",
    "        \n",
    "        raw_sample = self.raw_sample(batch_size, ep_inds, frame_inds)\n",
    "        batch = self._convert_raw_sample(raw_sample)\n",
    "        return batch\n",
    "\n",
    "    \n",
    "    def get_all_inds(self):\n",
    "        ep_lens = {i:len(ep) for i in  range(self.num_episodes)}\n",
    "        all_possible_inds = np.concatenate([[(ep_ind, frame_ind) \n",
    "                                             for frame_ind in range(ep_lens[ep_ind] - self.stride)] \n",
    "                                            for ep_ind in range(self.num_episodes)])\n",
    "        return all_possible_inds\n",
    "\n",
    "    \n",
    "    def raw_sample(self, ep_inds, frame_inds):\n",
    "        transitions = [self._sample(ep_ind,frame_ind, num, stride) for \n",
    "                                    ep_ind, frame_ind in zip(ep_inds,frame_inds)]\n",
    "        return transitions\n",
    "        \n",
    "    \n",
    "    \n",
    "    def _sample(self,ep_ind,frame_ind, num):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def _convert_raw_sample(self,transitions):\n",
    "        \"\"\"converts 8-bit RGB to float and pytorch tensor\"\"\"\n",
    "        # puts all trans objects into one trans object\n",
    "        trans = self._combine_transitions_into_one_big_one(transitions)\n",
    "        batch = self._convert_fields_to_pytorch_tensors(trans)\n",
    "        return batch\n",
    "        \n",
    "    def _combine_transitions_into_one_big_one(self,transitions):\n",
    "        fields = []\n",
    "        for i,field in enumerate(zip(*transitions)):\n",
    "            if isinstance(field[0],list):\n",
    "                new_field = np.stack([list_ for list_ in field])\n",
    "                if str(new_field.dtype) == \"bool\":\n",
    "                    new_field = new_field.astype(\"int\")\n",
    "                #print(field.shape,field)\n",
    "            if isinstance(field[0],dict):\n",
    "                new_field = {}\n",
    "                for k in field[0].keys():\n",
    "                    all_items_of_key_k = [dic[k] for dic in field]\n",
    "                    array_of_items_of_key_k = np.stack([list_ for list_ in all_items_of_key_k])\n",
    "                    new_field[k] = array_of_items_of_key_k\n",
    "\n",
    "            fields.append(new_field)\n",
    "        return Transition(*fields)\n",
    "    \n",
    "    def _convert_fields_to_pytorch_tensors(self,trans):\n",
    "        tb_dict = trans._asdict()\n",
    "        if \"state_param_dict\" in tb_dict:\n",
    "            for k,v  in trans.state_param_dict.items():\n",
    "                tb_dict[\"state_param_dict\"][k] = torch.tensor(v).to(self.DEVICE)\n",
    "                \n",
    "        \n",
    "        tb_dict[\"xs\"] = torch.stack([convert_frames(np.asarray(trans.xs[i]),to_tensor=True,resize_to=(-1,-1)) for\n",
    "                                                     i in range(len(trans.xs))]).to(self.DEVICE)\n",
    "        \n",
    "        if \"actions\" in tb_dict:\n",
    "            tb_dict[\"actions\"] = torch.from_numpy(np.asarray(trans.actions)).to(self.DEVICE)\n",
    "        if \"rewards\" in tb_dict:\n",
    "            tb_dict[\"rewards\"] = torch.from_numpy(np.asarray(trans.rewards)).to(self.DEVICE)\n",
    "\n",
    "        \n",
    "        \n",
    "        batch = Transition(*list(tb_dict.values()))\n",
    "        return batch\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Iterator that samples without replacement for replay buffer\n",
    "        It's basically like a standard sgd setup\n",
    "        If you want to sample with replacement like standard replay buffer use self.sample\"\"\"\n",
    "        all_inds = self.get_all_inds()\n",
    "        random.shuffle(all_inds)\n",
    "        size = len(all_inds)\n",
    "        for st in range(0, size, self.batch_size):\n",
    "            end = st+self.batch_size if st+self.batch_size <= size else size\n",
    "            batch_inds = np.stack(all_inds[st:end])\n",
    "            ep_inds, frame_inds = batch_inds[:,0], batch_inds[:,1]\n",
    "            raw_sample = self.raw_sample(ep_inds, frame_inds)\n",
    "            yield self._convert_raw_sample(raw_sample)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.episodes)\n",
    "    \n",
    "    @property\n",
    "    def num_episodes(self):\n",
    "        return self.__len__()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FramesSampler(DataSampler):\n",
    "    def __init__(self,args,batch_size):\n",
    "        super(FramesSampler,self).__init__(args, batch_size)\n",
    "    \n",
    "    def _sample(self,ep_ind,frame_ind, num=1, stride=1):\n",
    "        ep = episodes[ep_ind]\n",
    "        frames_to_go = len(ep.xs)  - frame_ind \n",
    "        frames_covered = num*stride\n",
    "        diff = frames_to_go - frames_covered\n",
    "        if diff < 0:\n",
    "            #print(frame_ind, diff)\n",
    "            frame_ind += diff\n",
    "        frames = []\n",
    "        for _ in range(num):\n",
    "            frame = ep._asdict()[\"xs\"][frame_ind]\n",
    "            frames.append(frame)\n",
    "            frame_ind += stride\n",
    "        trans = dc.get_transition_constructor()(xs=frames)\n",
    "        return trans\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = FramesSampler(args,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-02b26f8be57a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-511cd60b7e6e>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, batch_size, with_replacement)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m#sample indices into frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mall_inds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_inds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mall_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_inds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mep_inds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_inds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-511cd60b7e6e>\u001b[0m in \u001b[0;36mget_all_inds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m         all_possible_inds = np.concatenate([[(ep_ind, frame_ind) \n\u001b[1;32m     44\u001b[0m                                              for frame_ind in range(ep_lens[ep_ind] - self.stride)] \n\u001b[0;32m---> 45\u001b[0;31m                                             for ep_ind in range(self.num_episodes)])\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mall_possible_inds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "fs.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object.__init__() takes no parameters",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-6ad3b89c7f0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataSampler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: object.__init__() takes no parameters"
     ]
    }
   ],
   "source": [
    "super(DataSampler,fs).__init__(args,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m            super\n",
       "\u001b[0;31mString form:\u001b[0m     <super: <class 'DataSampler'>, <FramesSampler object>>\n",
       "\u001b[0;31mDocstring:\u001b[0m       The most base type\n",
       "\u001b[0;31mClass docstring:\u001b[0m\n",
       "super() -> same as super(__class__, <first argument>)\n",
       "super(type) -> unbound super object\n",
       "super(type, obj) -> bound super object; requires isinstance(obj, type)\n",
       "super(type, type2) -> bound super object; requires issubclass(type2, type)\n",
       "Typical use to call a cooperative superclass method:\n",
       "class C(B):\n",
       "    def meth(self, arg):\n",
       "        super().meth(arg)\n",
       "This works for class methods too:\n",
       "class C(B):\n",
       "    @classmethod\n",
       "    def cmeth(cls, arg):\n",
       "        super().cmeth(arg)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_arr = np.stack(random.choices(all_possible, k=32))\n",
    "\n",
    "ep_inds, frame_inds = all_arr[:,0], all_arr[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "\n",
    "class BufferFiller(object):\n",
    "    \"\"\"creates and fills replay buffers with transitions\"\"\"\n",
    "    def __init__(self,args,policy=None):\n",
    "        #self.env = env\n",
    "        self.args = args\n",
    "        self.policy=policy\n",
    "\n",
    "    def make_empty_buffer(self):\n",
    "        return ReplayMemory(batch_size=self.args.batch_size, args=self.args)\n",
    "    \n",
    "    def fill(self,size):\n",
    "        \"\"\"fill with transitions by just following a policy\"\"\"\n",
    "        buffer = self.make_empty_buffer()\n",
    "        collector = EpisodeCollector(args=self.args,policy=self.policy)\n",
    "        buffer = self._fill(size, collector, buffer)\n",
    "        return buffer \n",
    "    \n",
    "    def _fill(self,size, collector, buffer):\n",
    "        cur_size = 0\n",
    "        while cur_size < size:\n",
    "            episode = collector.collect_episode_per_the_policy()\n",
    "            cur_size += len(episode.xs)\n",
    "            buffer.push(episode)\n",
    "        return buffer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
